{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prediksi Welfare v2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryo14781470/UAS/blob/master/Prediksi_Welfare_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07EOMPPdq-DO"
      },
      "outputs": [],
      "source": [
        "# import package penting\n",
        "\n",
        "# untuk model machine learning\n",
        "from tensorflow import lite\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# untuk processing suara\n",
        "import sklearn\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "# untuk download dataset dari github\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# untuk general use\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "# from pathlib import Path # untuk buka current working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing dataset"
      ],
      "metadata": {
        "id": "zJrcKhdTxdYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hapus folder dataset sebelumnya\n",
        "!rm -rf \"/content/dataset\"\n",
        "# download dataset dari github, simpan di cwd (/content)\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/fawwazanvilen/Dataset-Vokalisasi-Ayam/archive/refs/heads/main.zip\" \\\n",
        "    -O \"/content/dataset.zip\"\n",
        "\n",
        "# ekstrak dataset di cwd (/content)\n",
        "zip_ref = zipfile.ZipFile(\"/content/dataset.zip\", \"r\") # buka file zip dalam mode read\n",
        "zip_ref.extractall(\"/content\") # ekstrak dataset di cwd\n",
        "zip_ref.close()\n",
        "\n",
        "# pindah dataset ke cwd\n",
        "!mv \"/content/Dataset-Vokalisasi-Ayam-main/dataset\" \"/content/dataset\"\n",
        "!rm -rf \"/content/Dataset-Vokalisasi-Ayam-main\""
      ],
      "metadata": {
        "id": "cZVncikIvvm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "934e95bc-5b3b-481d-e895-e62373a6ce1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-12 06:10:10--  https://github.com/fawwazanvilen/Dataset-Vokalisasi-Ayam/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/fawwazanvilen/Dataset-Vokalisasi-Ayam/zip/refs/heads/main [following]\n",
            "--2022-06-12 06:10:10--  https://codeload.github.com/fawwazanvilen/Dataset-Vokalisasi-Ayam/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.113.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.113.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/content/dataset.zip’\n",
            "\n",
            "/content/dataset.zi     [     <=>            ]  12.27M  12.0MB/s    in 1.0s    \n",
            "\n",
            "2022-06-12 06:10:11 (12.0 MB/s) - ‘/content/dataset.zip’ saved [12868262]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bikin file metadata\n",
        "dataset_path = \"/content/dataset\"\n",
        "json_path = \"data.json\"\n",
        "\n",
        "# dictionary untuk menyimpan hasil mapping, label, MFCC, dan files\n",
        "data = {\n",
        "    \"mapping\": [],\n",
        "    \"labels\": [],\n",
        "    \"MFCCs\": [],\n",
        "    \"files\": []\n",
        "}\n",
        "\n",
        "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "  # print(i, (dirpath, dirnames, filenames)) # mau ngecek apa yang terjadi\n",
        "  if dirpath is not dataset_path:\n",
        "\n",
        "    # masukkan path directory saat ini (yang bukan dataset_path, tapi level bawahnya)\n",
        "    # sebagai mapping dalam dictionary (label dalam bentuk numerik)\n",
        "    label = dirpath.split(\"/\")[-1]\n",
        "    data[\"mapping\"].append(label)\n",
        "    print(\"\\nProcessing: '{}'\".format(label))\n",
        "\n",
        "    # proses semua file audio di subdir dataset (happy, unhappy, greeting)\n",
        "    for f in filenames:\n",
        "      file_path = os.path.join(dirpath, f)\n",
        "      \n",
        "      # load file audio dan potong untuk memastikan panjang file audio konsisten\n",
        "      signal, sample_rate = librosa.load(file_path)\n",
        "\n",
        "      # sample_rate di dataset adalah 22050 Hz\n",
        "      # jumlah kanal di semua file audio adalah mono (bukan stereo), tidak perlu pemrosesan lagi\n",
        "      # print(sample_rate) # cek sample rate, untuk coba-coba (ternyata 22050 Hz semua)\n",
        "      # print(signal.shape) # cek apakah audio-nya mono/stereo (ternyata mono semua)\n",
        "\n",
        "      # supaya panjang file audio konsisten, semua file audio dioverlay dengan suara diam\n",
        "      # selama durasi tertentu\n",
        "      # durasi yang digunakan adalah 12 detik (12 kali sample_rate)\n",
        "      # karena data dengan durasi terpanjang dalam dataset adalah 12 detik\n",
        "      padding_array = np.zeros(12*sample_rate, dtype=float) # padding_array isi nol\n",
        "      signal.resize(padding_array.shape, refcheck=False)\n",
        "      signal = signal + padding_array\n",
        "\n",
        "      # drop file audio dengan jumlah sampel lebih sedikit dari durasi tertentu\n",
        "      # ambil durasi 4 detik (cek dulu)\n",
        "      if len(signal) >= 4*sample_rate:\n",
        "\n",
        "          # ensure consistency of the length of the signal\n",
        "          signal = signal[:4*sample_rate]\n",
        "\n",
        "          # extract MFCCs\n",
        "          num_mfcc=13\n",
        "          n_fft=2048\n",
        "          hop_length=512\n",
        "          MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                        hop_length=hop_length)\n",
        "\n",
        "          # store data for analysed track\n",
        "          data[\"MFCCs\"].append(MFCCs.T.tolist())\n",
        "          data[\"labels\"].append(i-1)\n",
        "          data[\"files\"].append(file_path)\n",
        "          print(\"{}: {}\".format(file_path, i-1))\n",
        "\n",
        "    # save data in json file\n",
        "    with open(json_path, \"w\") as fp:\n",
        "      json.dump(data, fp, indent=4)"
      ],
      "metadata": {
        "id": "9wwxuwqVzVof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ca3b8e-88db-424d-be4f-79035884e268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: 'Greeting'\n",
            "/content/dataset/Greeting/Whats_Up1.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me10.wav: 0\n",
            "/content/dataset/Greeting/Whats_Up3.wav: 0\n",
            "/content/dataset/Greeting/Whats_Up2.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me12.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me20.wav: 0\n",
            "/content/dataset/Greeting/Whats_Up6.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me6.wav: 0\n",
            "/content/dataset/Greeting/Whats_Up8.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me11.wav: 0\n",
            "/content/dataset/Greeting/Hello.wav: 0\n",
            "/content/dataset/Greeting/Whats_Up7.wav: 0\n",
            "/content/dataset/Greeting/Whats_Up5.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me3.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me19.wav: 0\n",
            "/content/dataset/Greeting/Whats_Up4.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me5.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me7.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me4.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me21.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me14.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me1.wav: 0\n",
            "/content/dataset/Greeting/Hello2.wav: 0\n",
            "/content/dataset/Greeting/Do_You_Have_Food_For_Me2.wav: 0\n",
            "\n",
            "Processing: 'Happy'\n",
            "/content/dataset/Happy/Tidbitting_Hen6.wav: 1\n",
            "/content/dataset/Happy/Tidbitting_Hen13.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating2.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating17.wav: 1\n",
            "/content/dataset/Happy/Tidbitting_Hen14.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating7.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating8.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating15.wav: 1\n",
            "/content/dataset/Happy/Tidbitting_Hen2.wav: 1\n",
            "/content/dataset/Happy/Egg_Song1.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating5.wav: 1\n",
            "/content/dataset/Happy/Tidbitting_Hen1.wav: 1\n",
            "/content/dataset/Happy/Tidbitting_Hen11.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating16.wav: 1\n",
            "/content/dataset/Happy/Tidbitting_Hen8.wav: 1\n",
            "/content/dataset/Happy/Egg_Song2.wav: 1\n",
            "/content/dataset/Happy/Tidbitting_Hen4.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating22.wav: 1\n",
            "/content/dataset/Happy/Tidbitting_Hen9.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating1.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating18.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating13.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating4.wav: 1\n",
            "/content/dataset/Happy/Tidbitting_Hen10.wav: 1\n",
            "/content/dataset/Happy/Tidbitting_Hen5.wav: 1\n",
            "/content/dataset/Happy/Tidbitting_Hen7.wav: 1\n",
            "/content/dataset/Happy/Tidbitting_Hen12.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating3.wav: 1\n",
            "/content/dataset/Happy/Happy_Eating9.wav: 1\n",
            "\n",
            "Processing: 'Unhappy'\n",
            "/content/dataset/Unhappy/Where Is Everyone3.wav: 2\n",
            "/content/dataset/Unhappy/Give_Me_Food2.wav: 2\n",
            "/content/dataset/Unhappy/I_Need_A_Nest_Box1.wav: 2\n",
            "/content/dataset/Unhappy/Give_Me_Food1.wav: 2\n",
            "/content/dataset/Unhappy/Where Is Everyone11.wav: 2\n",
            "/content/dataset/Unhappy/Im_Hungry1.wav: 2\n",
            "/content/dataset/Unhappy/Where_Is_Everyone8.wav: 2\n",
            "/content/dataset/Unhappy/Privacy_Please.wav: 2\n",
            "/content/dataset/Unhappy/Where Is Everyone7.wav: 2\n",
            "/content/dataset/Unhappy/Privacy_Please3.wav: 2\n",
            "/content/dataset/Unhappy/Privacy_Please4.wav: 2\n",
            "/content/dataset/Unhappy/Where Is Everyone5.wav: 2\n",
            "/content/dataset/Unhappy/Where Is Everyone13.wav: 2\n",
            "/content/dataset/Unhappy/Stop_It2.wav: 2\n",
            "/content/dataset/Unhappy/Where Is Everyone14.wav: 2\n",
            "/content/dataset/Unhappy/Im_Hungry2.wav: 2\n",
            "/content/dataset/Unhappy/Stop_It1.wav: 2\n",
            "/content/dataset/Unhappy/Im_Hungry.wav: 2\n",
            "/content/dataset/Unhappy/Where Is Everyone12.wav: 2\n",
            "/content/dataset/Unhappy/Where Is Everyone6.wav: 2\n",
            "/content/dataset/Unhappy/Where_Is_Everyone10.wav: 2\n",
            "/content/dataset/Unhappy/Privacy_Please2.wav: 2\n",
            "/content/dataset/Unhappy/Where Is Everyone1.wav: 2\n",
            "/content/dataset/Unhappy/Stop_It3.wav: 2\n",
            "/content/dataset/Unhappy/Where Is Everyone2.wav: 2\n",
            "/content/dataset/Unhappy/Where Is Everyone4.wav: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bikin Model"
      ],
      "metadata": {
        "id": "9yhlk7rwK4wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DATA_PATH = \"data.json\"\n",
        "SAVED_MODEL_PATH = \"model.h5\"\n",
        "EPOCHS = 70\n",
        "BATCH_SIZE = 8\n",
        "PATIENCE = 15\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "\n",
        "def load_data(data_path):\n",
        "    \"\"\"Loads training dataset from json file.\n",
        "    :param data_path (str): Path to json file containing data\n",
        "    :return X (ndarray): Inputs\n",
        "    :return y (ndarray): Targets\n",
        "    \"\"\"\n",
        "    with open(data_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "\n",
        "    X = np.array(data[\"MFCCs\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    print(\"Training sets loaded!\")\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def prepare_dataset(data_path, test_size=0.2, validation_size=0.2):\n",
        "    \"\"\"Creates train, validation and test sets.\n",
        "    :param data_path (str): Path to json file containing data\n",
        "    :param test_size (flaot): Percentage of dataset used for testing\n",
        "    :param validation_size (float): Percentage of train set used for cross-validation\n",
        "    :return X_train (ndarray): Inputs for the train set\n",
        "    :return y_train (ndarray): Targets for the train set\n",
        "    :return X_validation (ndarray): Inputs for the validation set\n",
        "    :return y_validation (ndarray): Targets for the validation set\n",
        "    :return X_test (ndarray): Inputs for the test set\n",
        "    :return X_test (ndarray): Targets for the test set\n",
        "    \"\"\"\n",
        "\n",
        "    # load dataset\n",
        "    X, y = load_data(data_path)\n",
        "\n",
        "    # create train, validation, test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
        "\n",
        "    # add an axis to nd array\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "    X_validation = X_validation[..., np.newaxis]\n",
        "\n",
        "    return X_train, y_train, X_validation, y_validation, X_test, y_test\n",
        "\n",
        "\n",
        "def build_model(input_shape, loss=\"sparse_categorical_crossentropy\", learning_rate=0.0001):\n",
        "    \"\"\"Build neural network using keras.\n",
        "    :param input_shape (tuple): Shape of array representing a sample train. E.g.: (44, 13, 1)\n",
        "    :param loss (str): Loss function to use\n",
        "    :param learning_rate (float):\n",
        "    :return model: TensorFlow model\n",
        "    \"\"\"\n",
        "\n",
        "    # build network architecture using convolutional layers\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # 1st conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=input_shape,\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
        "\n",
        "    # 2nd conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
        "\n",
        "    # 3rd conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2), padding='same'))\n",
        "\n",
        "    # flatten output and feed into dense layer\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "    tf.keras.layers.Dropout(0.1)\n",
        "\n",
        "    # softmax output layer\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "    optimiser = tf.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer=optimiser,\n",
        "                  loss=loss,\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    # print model parameters on console\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train(model, epochs, batch_size, patience, X_train, y_train, X_validation, y_validation):\n",
        "    \"\"\"Trains model\n",
        "    :param epochs (int): Num training epochs\n",
        "    :param batch_size (int): Samples per batch\n",
        "    :param patience (int): Num epochs to wait before early stop, if there isn't an improvement on accuracy\n",
        "    :param X_train (ndarray): Inputs for the train set\n",
        "    :param y_train (ndarray): Targets for the train set\n",
        "    :param X_validation (ndarray): Inputs for the validation set\n",
        "    :param y_validation (ndarray): Targets for the validation set\n",
        "    :return history: Training history\n",
        "    \"\"\"\n",
        "\n",
        "    earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", min_delta=0.001, patience=patience)\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(X_validation, y_validation),\n",
        "                        callbacks=[earlystop_callback])\n",
        "    return history\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
        "    :param history: Training history of model\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy subplot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
        "    axs[0].plot(history.history['val_accuracy'], label=\"val_accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy evaluation\")\n",
        "\n",
        "    # create loss subplot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"loss\")\n",
        "    axs[1].plot(history.history['val_loss'], label=\"val_loss\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].set_ylabel(\"Loss\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Loss evaluation\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def main():\n",
        "    # generate train, validation and test sets\n",
        "    X_train, y_train, X_validation, y_validation, X_test, y_test = prepare_dataset(DATA_PATH)\n",
        "\n",
        "    # create network\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "    model = build_model(input_shape, learning_rate=LEARNING_RATE)\n",
        "\n",
        "    # train network\n",
        "    history = train(model, EPOCHS, BATCH_SIZE, PATIENCE, X_train, y_train, X_validation, y_validation)\n",
        "\n",
        "    # plot accuracy/loss for training/validation set as a function of the epochs\n",
        "    plot_history(history)\n",
        "\n",
        "    # evaluate network on test set\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "    print(\"\\nTest loss: {}, test accuracy: {}\".format(test_loss, 100*test_acc))\n",
        "\n",
        "    # save model\n",
        "    model.save(SAVED_MODEL_PATH)\n",
        "\n",
        "    \n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "iYPbudqFE3Z1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cde6f5e8-56b2-4e45-aff5-fdcf15002771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sets loaded!\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 171, 11, 128)      1280      \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 171, 11, 128)     512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 86, 6, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 84, 4, 64)         73792     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 84, 4, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 42, 2, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 41, 1, 32)         8224      \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 41, 1, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 21, 1, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 672)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                43072     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 127,459\n",
            "Trainable params: 127,011\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "Epoch 1/70\n",
            "7/7 [==============================] - 2s 124ms/step - loss: 1.7232 - accuracy: 0.3600 - val_loss: 2.2219 - val_accuracy: 0.2308\n",
            "Epoch 2/70\n",
            "7/7 [==============================] - 1s 92ms/step - loss: 1.1710 - accuracy: 0.5600 - val_loss: 2.1500 - val_accuracy: 0.0769\n",
            "Epoch 3/70\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 0.9688 - accuracy: 0.6800 - val_loss: 2.1237 - val_accuracy: 0.0769\n",
            "Epoch 4/70\n",
            "7/7 [==============================] - 1s 89ms/step - loss: 0.7529 - accuracy: 0.8000 - val_loss: 1.9587 - val_accuracy: 0.1538\n",
            "Epoch 5/70\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 0.6315 - accuracy: 0.8600 - val_loss: 1.7298 - val_accuracy: 0.2308\n",
            "Epoch 6/70\n",
            "7/7 [==============================] - 1s 89ms/step - loss: 0.5256 - accuracy: 0.9000 - val_loss: 1.4901 - val_accuracy: 0.3846\n",
            "Epoch 7/70\n",
            "7/7 [==============================] - 1s 91ms/step - loss: 0.4971 - accuracy: 0.9200 - val_loss: 1.3417 - val_accuracy: 0.4615\n",
            "Epoch 8/70\n",
            "7/7 [==============================] - 1s 86ms/step - loss: 0.3908 - accuracy: 0.9800 - val_loss: 1.2679 - val_accuracy: 0.4615\n",
            "Epoch 9/70\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 0.4084 - accuracy: 0.9600 - val_loss: 1.2262 - val_accuracy: 0.4615\n",
            "Epoch 10/70\n",
            "7/7 [==============================] - 1s 89ms/step - loss: 0.3615 - accuracy: 0.9400 - val_loss: 1.1968 - val_accuracy: 0.4615\n",
            "Epoch 11/70\n",
            "7/7 [==============================] - 1s 89ms/step - loss: 0.3196 - accuracy: 0.9800 - val_loss: 1.1460 - val_accuracy: 0.4615\n",
            "Epoch 12/70\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 0.3080 - accuracy: 0.9800 - val_loss: 1.1152 - val_accuracy: 0.4615\n",
            "Epoch 13/70\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 0.2748 - accuracy: 1.0000 - val_loss: 1.0814 - val_accuracy: 0.4615\n",
            "Epoch 14/70\n",
            "7/7 [==============================] - 1s 91ms/step - loss: 0.2543 - accuracy: 1.0000 - val_loss: 1.0297 - val_accuracy: 0.4615\n",
            "Epoch 15/70\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 0.2710 - accuracy: 1.0000 - val_loss: 0.9962 - val_accuracy: 0.4615\n",
            "Epoch 16/70\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 0.2501 - accuracy: 1.0000 - val_loss: 0.9769 - val_accuracy: 0.5385\n",
            "Epoch 17/70\n",
            "7/7 [==============================] - 1s 89ms/step - loss: 0.2290 - accuracy: 1.0000 - val_loss: 0.9822 - val_accuracy: 0.5385\n",
            "Epoch 18/70\n",
            "7/7 [==============================] - 1s 89ms/step - loss: 0.2454 - accuracy: 1.0000 - val_loss: 0.9835 - val_accuracy: 0.6154\n",
            "Epoch 19/70\n",
            "7/7 [==============================] - 1s 89ms/step - loss: 0.2414 - accuracy: 0.9800 - val_loss: 0.9611 - val_accuracy: 0.6154\n",
            "Epoch 20/70\n",
            "7/7 [==============================] - 1s 93ms/step - loss: 0.2328 - accuracy: 0.9800 - val_loss: 0.9144 - val_accuracy: 0.6154\n",
            "Epoch 21/70\n",
            "7/7 [==============================] - 1s 89ms/step - loss: 0.1986 - accuracy: 1.0000 - val_loss: 0.8875 - val_accuracy: 0.6154\n",
            "Epoch 22/70\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 0.2113 - accuracy: 1.0000 - val_loss: 0.8864 - val_accuracy: 0.6154\n",
            "Epoch 23/70\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 0.2380 - accuracy: 1.0000 - val_loss: 0.8564 - val_accuracy: 0.6154\n",
            "Epoch 24/70\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 0.2043 - accuracy: 1.0000 - val_loss: 0.8569 - val_accuracy: 0.6154\n",
            "Epoch 25/70\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 0.1885 - accuracy: 1.0000 - val_loss: 0.8452 - val_accuracy: 0.6154\n",
            "Epoch 26/70\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 0.1892 - accuracy: 1.0000 - val_loss: 0.8454 - val_accuracy: 0.6154\n",
            "Epoch 27/70\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 0.1965 - accuracy: 1.0000 - val_loss: 0.8460 - val_accuracy: 0.6154\n",
            "Epoch 28/70\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 0.1933 - accuracy: 1.0000 - val_loss: 0.8357 - val_accuracy: 0.6154\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 57ms/step - loss: 0.8405 - accuracy: 0.7500\n",
            "\n",
            "Test loss: 0.840488612651825, test accuracy: 75.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediksi Model"
      ],
      "metadata": {
        "id": "uUQsnzWnK704"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "SAVED_MODEL_PATH = \"model.h5\"\n",
        "#SAMPLES_TO_CONSIDER = 22050 # ga diperlukan\n",
        "\n",
        "class _Keyword_Spotting_Service:\n",
        "    \"\"\"Singleton class for keyword spotting inference with trained models.\n",
        "    :param model: Trained model\n",
        "    \"\"\"\n",
        "\n",
        "    model = None\n",
        "    # _mapping = [\n",
        "    #     \"happy\",\n",
        "    #     \"greeting\",\n",
        "    #     \"unhappy\"\n",
        "    # ]\n",
        "    _mapping = [\n",
        "        \"greeting\",\n",
        "        \"happy\",\n",
        "        \"unhappy\"\n",
        "    ]\n",
        "    _instance = None\n",
        "\n",
        "\n",
        "    def predict(self, file_path):\n",
        "        \"\"\"\n",
        "        :param file_path (str): Path to audio file to predict\n",
        "        :return predicted_keyword (str): Keyword predicted by the model\n",
        "        \"\"\"\n",
        "\n",
        "        # extract MFCC\n",
        "        MFCCs = self.preprocess(file_path)\n",
        "\n",
        "        # we need a 4-dim array to feed to the model for prediction: (# samples, # time steps, # coefficients, 1)\n",
        "        MFCCs = MFCCs[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "        # get the predicted label\n",
        "        predictions = self.model.predict(MFCCs)\n",
        "        print(predictions)\n",
        "        predicted_index = np.argmax(predictions)\n",
        "        print(predicted_index)\n",
        "        predicted_keyword = self._mapping[predicted_index]\n",
        "        return predicted_keyword\n",
        "\n",
        "\n",
        "    def preprocess(self, file_path, num_mfcc=13, n_fft=2048, hop_length=512):\n",
        "        \"\"\"Extract MFCCs from audio file.\n",
        "        :param file_path (str): Path of audio file\n",
        "        :param num_mfcc (int): # of coefficients to extract\n",
        "        :param n_fft (int): Interval we consider to apply STFT. Measured in # of samples\n",
        "        :param hop_length (int): Sliding window for STFT. Measured in # of samples\n",
        "        :return MFCCs (ndarray): 2-dim array with MFCC data of shape (# time steps, # coefficients)\n",
        "        \"\"\"\n",
        "\n",
        "        # # load audio file\n",
        "        # signal, sample_rate = librosa.load(file_path)\n",
        "\n",
        "        # if len(signal) >= SAMPLES_TO_CONSIDER:\n",
        "        #     # ensure consistency of the length of the signal\n",
        "        #     signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "\n",
        "        #     # extract MFCCs\n",
        "        #     MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "        #                                  hop_length=hop_length)\n",
        "            \n",
        "        # load file audio dan potong untuk memastikan panjang file audio konsisten\n",
        "        signal, sample_rate = librosa.load(file_path)\n",
        "\n",
        "        # sample_rate di dataset adalah 22050 Hz\n",
        "        # jumlah kanal di semua file audio adalah mono (bukan stereo), tidak perlu pemrosesan lagi\n",
        "        # print(sample_rate) # cek sample rate, untuk coba-coba (ternyata 22050 Hz semua)\n",
        "        # print(signal.shape) # cek apakah audio-nya mono/stereo (ternyata mono semua)\n",
        "\n",
        "        # supaya panjang file audio konsisten, semua file audio dioverlay dengan suara diam\n",
        "        # selama durasi tertentu\n",
        "        # durasi yang digunakan adalah 12 detik (12 kali sample_rate)\n",
        "        # karena data dengan durasi terpanjang dalam dataset adalah 12 detik\n",
        "        padding_array = np.zeros(12*sample_rate, dtype=float) # padding_array isi nol\n",
        "        signal.resize(padding_array.shape, refcheck=False)\n",
        "        signal = signal + padding_array\n",
        "\n",
        "        # drop audio files with less than pre-decided number of samples\n",
        "        # drop file audio dengan jumlah sampel lebih sedikit dari durasi tertentu\n",
        "        # ambil durasi 4 detik (cek dulu)\n",
        "        if len(signal) >= 4*sample_rate:\n",
        "\n",
        "            # ensure consistency of the length of the signal\n",
        "            signal = signal[:4*sample_rate]\n",
        "\n",
        "            # extract MFCCs\n",
        "            num_mfcc=13\n",
        "            n_fft=2048\n",
        "            hop_length=512\n",
        "            MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                        hop_length=hop_length)\n",
        "        return MFCCs.T\n",
        "\n",
        "\n",
        "def Keyword_Spotting_Service():\n",
        "    \"\"\"Factory function for Keyword_Spotting_Service class.\n",
        "    :return _Keyword_Spotting_Service._instance (_Keyword_Spotting_Service):\n",
        "    \"\"\"\n",
        "\n",
        "    # ensure an instance is created only the first time the factory function is called\n",
        "    if _Keyword_Spotting_Service._instance is None:\n",
        "        _Keyword_Spotting_Service._instance = _Keyword_Spotting_Service()\n",
        "        _Keyword_Spotting_Service.model = tf.keras.models.load_model(SAVED_MODEL_PATH)\n",
        "    return _Keyword_Spotting_Service._instance\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # create 2 instances of the keyword spotting service\n",
        "    kss = Keyword_Spotting_Service()\n",
        "    kss1 = Keyword_Spotting_Service()\n",
        "\n",
        "    # check that different instances of the keyword spotting service point back to the same object (singleton)\n",
        "    assert kss is kss1\n",
        "\n",
        "    # make a prediction\n",
        "    keyword = kss.predict(\"/content/dataset/Happy/Egg_Song1.wav\")\n",
        "    #keyword = kss.predict(\"/content/dataset/Unhappy/I_Need_A_Nest_Box1.wav\")\n",
        "    #keyword = kss.predict(\"/content/dataset/Greeting/Whats_Up2.wav\")\n",
        "    print(keyword)"
      ],
      "metadata": {
        "id": "KbCyim-IFB1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coba satu-satu\n",
        "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "  # print(i, (dirpath, dirnames, filenames)) # mau ngecek apa yang terjadi\n",
        "  if dirpath is not dataset_path:\n",
        "\n",
        "    # masukkan path directory saat ini (yang bukan dataset_path, tapi level bawahnya)\n",
        "    # sebagai mapping dalam dictionary (label dalam bentuk numerik)\n",
        "    label = dirpath.split(\"/\")[-1]\n",
        "    data[\"mapping\"].append(label)\n",
        "    print(\"\\nProcessing: '{}'\".format(label))\n",
        "\n",
        "    # proses semua file audio di subdir dataset (happy, unhappy, greeting)\n",
        "    for f in filenames:\n",
        "      file_path = os.path.join(dirpath, f)\n",
        "      keyword = kss.predict(file_path)\n",
        "      print(keyword)"
      ],
      "metadata": {
        "id": "HumaMC5iFSfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# augmentasi audio, bisa pakai frequency/time shift"
      ],
      "metadata": {
        "id": "ACxwKi7tB_9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ubah ke mel spectogram, pakai mfcc"
      ],
      "metadata": {
        "id": "xXF_r7C7CD_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# augmentasi spectogram (?)"
      ],
      "metadata": {
        "id": "Vc3ZWsXNCHbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bikin model\n",
        "# training model, cek performansi"
      ],
      "metadata": {
        "id": "t5ZPS4s5CJd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coba model untuk prediksi"
      ],
      "metadata": {
        "id": "IoWvqxU7CNx8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}